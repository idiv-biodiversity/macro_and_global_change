---
title: "Downloading occurrences from GBIF"
output:  html_document
---

```{r global_options, include=FALSE}
knitr::opts_chunk$set(fig.width=12, fig.height=8, eval = FALSE,
                      echo=TRUE, warning=FALSE, message=FALSE,
                      tidy = TRUE, collapse = TRUE,
                      results = 'hold')
```

## Background
The public availability of species distribution data has increased substantially in the last 10 years: occurrence information, mostly in the form of geographic coordinate records for species across the tree of life, representing hundreds of years of biological collection effort are now available. The global Biodiversity Information Facility (www.gbif.org) is one of the largest data providers, hosting more than 1.4 billion records (June 2020) from a large variety of sources.

## Outcomes
After this exercise you will be able to retrieve species occurrence information from GBIF from within R. You will be equipt with example data from your group of interest for the follow upcoming exercises. See https://ropensci.org/tutorials/rgbif_tutorial.html for a more exhaustive tutorial on the rgbif package.

## Exercise
We will use the rgbif package to obtain occurrence records from GBIF. You can find the relevant functions for each task in the parentheses. You can get help on each function by typing `?FUNCTIONNAME`. 


1. Familiarize yourself with the `rgbif` package and download the occurrence data for one of the species of your choice. (`name_suggest`, `occ_Search`)
2. Look at the data and a quick plot (`head`, `plot`).
3. Now find out how many occurrences for example group there are from Tanzania.  (`name_suggest`, `occ_count`)
4. Download all records for the species from the example species [list] (). Make sure to keep an eye on the `limit` argument. (`occ_search`)
5. Save the downloaded data as .txt or .csv to the working directory. (`write_csv`, `write_delim`)

## Library setup
In this exercise we will use the rgbif library for communication with GBIF and the tidyverse library for data management.

```{r setup, include=FALSE}
library(rgbif)
library(tidyverse)
library(rgdal)
library(rgeos)
```

# Tutorial
In the following tutorial, we will go through the questions one-by-one. The suggested answers are by no means the only correct ones.

## 1. Download data for a single species we saw in the filedand save them in a data.frame
GBIF hosts a large number of records and downloading all records might take some time (also the download limit using `occ_search` is 250,000), so it is worth checking first how many records are available. We do this using the `return` argument of the `occ_search` function, which will only return meta-data on the record. Chose a species from your project taxon, for demonstration will today use a group of East African frogs. We'll first download data for Pickersgill's banana frog, _Afrixalus delicatus_:

```{r occ_count}
#Search occurrence records
dat <- occ_search(scientificName = "Afrixalus delicatus", 
                   return =  "data", limit = 1000)
```

## 2. Explore the downloaded data
```{r}
nrow(dat) # Check the number of records
head(dat) # Check the data
plot(dat$decimalLatitude ~ dat$decimalLongitude) # Look at the georeferenced records
```

So luckily there are a good number of records available. An as the quick visualization shows, a lot of the have geographic coordinates. In the next exercise we will see how to reduce the amount of information and quality check the data. But letâ€™s first download more relevant data for the project.

## 3. How many records are available for your group of interest?
Today, we are interested not only in one species, but a larger taxonomic group (. You can search for higher rank taxa using GBIF's taxonKey. The taxonKey is a unique identifier for each taxon; we can obtain it from the taxon name via the `name _suggest` function. Since higher taxa might have a lot of records and downloading might take a lot of time, we will first check how many records are available. Here we will look at the entire family of frogs Hyperoliidae.

```{r}
#Use the name_suggest function to get the gbif taxon key
tax_key <- name_suggest(q = "Hyperoliidae", rank = "Family")

#Sometimes groups have multiple taxon keys, in this case three, so we will check how many records are available for them
lapply(tax_key$key, "occ_count")

#Here the firsrt one is relevant, check for your group!
tax_key <- tax_key$key[1]
```

We can then check how many records are available for this family from a specific country, for instance TAnzania

```{r}
occ_count(tax_key, country = "TZ")
```

There are more than five thousand records available from Tanzania. This is well within the limit for of  200,000 records of `occ_Search`.

4. Download all data for the example group from Tanzania, or if the group is very large from part of that area.
You can now download the records for Tanzania. Since we want to work with coordinates, we will only download those records that do have coordinates.
```{r}
dat  <- occ_search(taxonKey = tax_key, return = "data",
                   country = "TZ", hasCoordinate = T, limit = 6000)
```

That leaves us with 6000 records. Another option to limit the spatial extent independent of county border is using a polygon. To do this you can use the Well-known-text format (WKT) to specify an area. Here we use a very simple rectangle, feel free to experiment. The download may take some minutes.

```{r, eval=FALSE}
study_a <- "POLYGON((50 10, 25 10, 25 -30, 50 -30, 50 10))"

dat_ne  <- occ_search(taxonKey = tax_key, return = "data", hasCoordinate = T,
                   geometry = study_a, limit = 1000) 

```

Alternatively, you can download data for a list of taxa. For the following exercises, we want to download data for all lowland East African Frogs. You can find the list on [GitHub].This download will take c. 10 minutes.

```{r, eval=FALSE}
gen_list <- read_delim("inst/species_list.txt", delim = "\t", quote = "")

tax_key <- lapply(gen_list$species, function(k){name_suggest(q = k, rank = "species")})
tax_key <- unlist(lapply(tax_key, "[[", "key"))

unlist(lapply(tax_key, "occ_count"))

dat_ne  <- occ_search(taxonKey = tax_key, return = "data", hasCoordinate = T,
                   limit = 9000) 
dat_ne <- lapply(dat_ne, "as.data.frame")

dat_ne <- bind_rows(dat_ne)
```


5. Save the downloaded data as .csv to the working directory.
You can save the results as text file to the working directory. To identify your working directory use `getwd()`. You will use these records for the next exercises and the species distribution modelling on Thursday.

```{r}
write_csv(dat_ne, path = "inst/gbif_occurrences.csv")
```

If you want to use records from GBIF for publication, please make sure you cite them properly, using a DOI, you can get a DOI by using `occ_download`.